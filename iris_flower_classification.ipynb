{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "74b8d3fe",
   "metadata": {},
   "source": [
    "## 1. Import dependencies\n",
    "Import standard data science and ML libraries: NumPy, Pandas, Matplotlib, Seaborn, Scikit-Learn and joblib to save the best model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f1fda29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data science imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# scikit-learn imports\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# utility\n",
    "import joblib\n",
    "\n",
    "# visualization settings\n",
    "%matplotlib inline\n",
    "sns.set(style=\"whitegrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2d72123",
   "metadata": {},
   "source": [
    "## 2. Load dataset and show first few rows\n",
    "Load the Iris dataset from scikit-learn and convert it to a pandas DataFrame for easier analysis.\n",
    "We will also add a `species` column using the target names for readability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e91f7b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Iris dataset from scikit-learn\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "feature_names = iris.feature_names\n",
    "target_names = iris.target_names\n",
    "\n",
    "# Create pandas DataFrame for a cleaner view\n",
    "df = pd.DataFrame(X, columns=feature_names)\n",
    "df['species'] = pd.Categorical.from_codes(y, target_names)\n",
    "\n",
    "# Display first 5 rows\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5655a9ba",
   "metadata": {},
   "source": [
    "## 3. Dataset info, shape, null-check, basic statistics\n",
    "Quick checks to ensure dataset health and basic properties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0687ebc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# General info\n",
    "print('Shape:', df.shape)\n",
    "print('\n",
    "Column info:')\n",
    "print(df.info())\n",
    "\n",
    "# Check nulls and basic stats\n",
    "print('\n",
    "Null values:')\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Summary statistics\n",
    "df.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c57351d",
   "metadata": {},
   "source": [
    "## 4. Exploratory Data Analysis (EDA)\n",
    "Let's visualize the dataset to discover patterns, relationships and class separation.\n",
    "We'll create: pairplot, correlation heatmap, and distribution plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3d613fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pairplot shows relationships between features colored by species\n",
    "sns.pairplot(df, hue='species', corner=True, height=1.6);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b09ac62e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation matrix heatmap\n",
    "plt.figure(figsize=(8,6))\n",
    "corr = df.drop('species', axis=1).corr()\n",
    "sns.heatmap(corr, annot=True, cmap='coolwarm')\n",
    "plt.title('Feature Correlation Heatmap')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67e11e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution and box plots for features\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 8))\n",
    "for ax, feature in zip(axes.ravel(), feature_names):\n",
    "    sns.histplot(data=df, x=feature, hue='species', ax=ax, bins=15, kde=True)\n",
    "    ax.set_title(f'Distribution of {feature}')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8b73ee6",
   "metadata": {},
   "source": [
    "## 5. Data preprocessing\n",
    "- Convert category labels to numeric if needed (already numeric in `y`).\n",
    "- No missing values in Iris dataset; scale features if desired.\n",
    "We will proceed by splitting the dataset into train and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f86c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing: create X (features) and y (labels) as numpy arrays or data frames\n",
    "X = df[feature_names]\n",
    "y = df['species']  # categorical names\n",
    "\n",
    "# Optional: check distribution of classes\n",
    "print('Class counts:')\n",
    "print(y.value_counts())\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "print('\n",
    "Train size:', X_train.shape)\n",
    "print('Test size:', X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c931af5",
   "metadata": {},
   "source": [
    "## 6. Train multiple classification models\n",
    "We'll train four simple, well-known models and compare their performance: Logistic Regression, SVM, Decision Tree, and Random Forest.\n",
    "We use default hyperparameters as a starting point (good for a small dataset)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "666a56ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and train models\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(solver='liblinear', random_state=42),\n",
    "    'SVM': SVC(kernel='rbf', probability=True, random_state=42),\n",
    "    'Decision Tree': DecisionTreeClassifier(random_state=42),\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "}\n",
    "\n",
    "trained_models = {}\n",
    "results = []\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    cr = classification_report(y_test, y_pred, output_dict=True)\n",
    "    trained_models[name] = model\n",
    "    results.append({\n",
    "        'Model': name,\n",
    "        'Accuracy': round(acc, 4),\n",
    "        'Confusion Matrix': cm,\n",
    "        'Classification Report': cr\n",
    "    })\n",
    "\n",
    "# Create results DataFrame\n",
    "results_df = pd.DataFrame([{'Model': r['Model'], 'Accuracy': r['Accuracy']} for r in results])\n",
    "results_df = results_df.sort_values(by='Accuracy', ascending=False).reset_index(drop=True)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c6c0736",
   "metadata": {},
   "source": [
    "## 7. Evaluate models: accuracy, confusion matrix & classification report\n",
    "Let's print detailed evaluation metrics for each classifier and visualize the best one using a confusion matrix heatmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63ac86cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print evaluation details\n",
    "for r in results:\n",
    "    print('Model:', r['Model'])\n",
    "    print('Accuracy:', r['Accuracy'])\n",
    "    print('Confusion Matrix:')\n",
    "    print(r['Confusion Matrix'])\n",
    "    print('\n",
    "Classification Report:')\n",
    "    print(pd.DataFrame(r['Classification Report']).T)\n",
    "    print('\n",
    "' + '-'*60 + '\n",
    "')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0d08460",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize confusion matrix for the best model (highest accuracy)\n",
    "best_model_name = results_df.iloc[0]['Model']\n",
    "best_model = trained_models[best_model_name]\n",
    "y_pred_best = best_model.predict(X_test)\n",
    "cm_best = confusion_matrix(y_test, y_pred_best)\n",
    "\n",
    "plt.figure(figsize=(6,5))\n",
    "sns.heatmap(cm_best, annot=True, fmt='d', cmap='Blues', xticklabels=target_names, yticklabels=target_names)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title(f'Confusion Matrix: {best_model_name}')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74bb1181",
   "metadata": {},
   "source": [
    "## 8. Choose the best model and explain why\n",
    "We choose the model with the highest accuracy and balanced performance across classes. If multiple models tie, consider preferred criteria like f1-score and model interpretability."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9daf22ca",
   "metadata": {},
   "source": [
    "## 9. Save the best model using joblib\n",
    "We'll save the best model to `iris_best_model.joblib` so it can be loaded later without retraining."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b64241c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save best model\n",
    "save_path = 'iris_best_model.joblib'\n",
    "joblib.dump(best_model, save_path)\n",
    "print(f'Best model ({best_model_name}) saved to {save_path}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83318493",
   "metadata": {},
   "source": [
    "## 10. Create a predict() helper function for sample input\n",
    "We'll write a simple function to load the saved model and predict the species for a new sample (single observation). This is useful for integrating the model into apps or for sharing with others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbea21f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_sample(features, model_path=save_path):\n",
    "    \"\"\"\n",
    "    Predict species for a single input sample.\n",
    "\n",
    "    Args:\n",
    "        features: list, tuple or numpy array of 4 feature values [sepal length, sepal width, petal length, petal width]\n",
    "        model_path: path to the saved model file\n",
    "\n",
    "    Returns:\n",
    "        predicted species name\n",
    "    \"\"\"\n",
    "    # Load model\n",
    "    model = joblib.load(model_path)\n",
    "    # Ensure it is a 2D array for sklearn\n",
    "    arr = np.array(features).reshape(1, -1)\n",
    "    pred = model.predict(arr)\n",
    "    return pred[0]\n",
    "\n",
    "# Example usage\n",
    "sample = [5.1, 3.5, 1.4, 0.2]  # small iris sample\n",
    "predicted = predict_sample(sample)\n",
    "print('Sample:', sample, '-> Predicted species:', predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8f07014",
   "metadata": {},
   "source": [
    "## 11. Final summary and observations\n",
    "- We successfully trained and compared 4 models on the Iris dataset.\n",
    "- We selected the best performing model based on accuracy and class-wise metrics.\n",
    "- The best model was saved to disk and a small `predict_sample()` function was provided for predictions.\n",
    "\n",
    "**Key observations:**\n",
    "- Iris is a small and well-balanced dataset; a simple ensemble like Random Forest or even Logistic Regression achieves high accuracy.\n",
    "- Visual EDA (pairplots and heatmaps) revealed feature separability and correlation patterns.\n",
    "\n",
    "Thanks for viewing this notebook â€” suitable for a data science portfolio/assignment with clean code, professional markdown, and reproducible steps."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
